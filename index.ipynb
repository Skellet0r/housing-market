{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"font-size:2em;\">Final Project Submission</b>\n",
    "\n",
    "* Student name: Edward Amor \n",
    "* Student pace: part time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: Victor Geislinger\n",
    "* Blog post URL: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A real estate company in the King County area wants to investigate house sales in order to predict pricing. Our task is to clean, explore, and model the housing data they have supplied to us in `kc_house_data.csv`, and identify house features which significantly effect house price. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To identify which house features significantly effect house price, we will use standard EDA practices, hypothesis testing, and regression modeling to come to our conclusions.\n",
    "\n",
    "For our client's consumption the results of our analysis will be condensed into a presentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our goal is to generate a multivariate linear regression model which as accurately as possible predicts the sale price of houses.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Data Acquisition\n",
    "2. Data Understanding\n",
    "  - Data Cleaning\n",
    "  - Data Exploration\n",
    "  - Data Visualization\n",
    "3. Modeling\n",
    "  - Feature Engineering\n",
    "    - Feature Transformation\n",
    "    - Feature Selection\n",
    "  - Training\n",
    "  - Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The data for this project can be found in the file `kc_house_data.csv`.\n",
    "\n",
    "Within this repository is also `data_dictionary.csv` which describes the data features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "According to our data dictionary the features of our dataset are as follows:\n",
    "\n",
    "| column        | description                                                  |\n",
    "| ------------- | ------------------------------------------------------------ |\n",
    "| id            | unique identified for a house                                |\n",
    "| date          | Date house was sold                                          |\n",
    "| price         | Price is prediction target                                   |\n",
    "| bedrooms      | Number of Bedrooms/House                                     |\n",
    "| bathrooms     | Number of bathrooms/bedrooms                                 |\n",
    "| sqft_living   | square footage of the home                                   |\n",
    "| sqft_lot      | square footage of the lot                                    |\n",
    "| floors        | Total floors (levels) in house                               |\n",
    "| waterfront    | House which has a view to a waterfront                       |\n",
    "| view          | Has been viewed                                              |\n",
    "| condition     | How good the condition is ( Overall )                        |\n",
    "| grade         | overall grade given to the housing unit                      |\n",
    "| sqft_above    | square footage of house apart from basement                  |\n",
    "| sqft_basement | square footage of the basement                               |\n",
    "| yr_built      | Built Year                                                   |\n",
    "| yr_renovated  | Year when house was renovated                                |\n",
    "| zipcode       | zip                                                          |\n",
    "| lat           | Latitude coordinate                                          |\n",
    "| long          | Longitude coordinate                                         |\n",
    "| sqft_living15 | The square footage of interior housing living space for the nearest 15 neighbors |\n",
    "| sqft_lot15    | The square footage of the land lots of the nearest 15 neighbors |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Of the 20 columns most notable is the price feature which will be our target during linear regression.\n",
    "\n",
    "Another thing to note is we have location data. This could be used to provide some insight into pricing by location, but may also be of use when delivering key information to our client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For this section we will inspect our dataset cleaning up inconsistencies such as, null values, duplicates, and incorrect data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:49.306318Z",
     "start_time": "2020-05-22T19:54:48.453045Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:49.402055Z",
     "start_time": "2020-05-22T19:54:49.307837Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# read in dataframe and output dataframe info\n",
    "df = pd.read_csv(\"kc_house_data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our raw dataset contains **21597 records**, and has **21 features**.\n",
    "\n",
    "The data types found within our dataset are: `float64`, `int64`, `object`.\n",
    "\n",
    "Next we will inspect our features more closely, especially the ones which are of `object` data type. Just to make sure they're the correct data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:49.434003Z",
     "start_time": "2020-05-22T19:54:49.404212Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Output the first 5 rows\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `date` column should be transformed to the `datetime` data type instead of `object`.\n",
    "\n",
    "The `sqft_basement` column needs to be further inspected, the values appear to be `float` there may be some `string` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:49.469076Z",
     "start_time": "2020-05-22T19:54:49.435638Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert date column from string data type to a datetime\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:49.477134Z",
     "start_time": "2020-05-22T19:54:49.470351Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# inspect the values of the sqft_basement column\n",
    "display(df['sqft_basement'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There is a '?' value, this may mean that the value is unknown. We will replace this with a null value, and then convert the column into a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:49.490157Z",
     "start_time": "2020-05-22T19:54:49.478319Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# replace ? with np.nan in the sqft_basement column and convert the column to float\n",
    "df['sqft_basement'] = df['sqft_basement'].replace('?', np.nan).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:49.501858Z",
     "start_time": "2020-05-22T19:54:49.492013Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# redisplay the values in the sqft_basement column\n",
    "display(df['sqft_basement'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "All our columns are now numeric, it's time to inspect for any interesting anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Inspecting Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:59.170104Z",
     "start_time": "2020-05-22T19:54:49.504818Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot a distribution plot for each feature\n",
    "fig, ax = plt.subplots(7, 3, figsize=(16, 9*3)) # 21 sub plots\n",
    "\n",
    "for col, axes in zip(df.columns, ax.flatten()):\n",
    "    sns.distplot(df[col], kde=False, rug=True, ax=axes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Columns to disregard when cleaning:\n",
    "\n",
    "- `id`\n",
    "- `date`\n",
    "- `long`\n",
    "- `lat`\n",
    "- `zipcode`\n",
    "\n",
    "From the histograms it looks like we may want to drop the `yr_renovated` column, we will have to investigate further.\n",
    "\n",
    "There are quite a few columns which should be transformed into the `categorical` data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Impute Inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### yr_renovated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:59.542858Z",
     "start_time": "2020-05-22T19:54:59.171697Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# inspect the yr_renovated column by plotting a violinplot\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "sns.violinplot('yr_renovated', data=df, width=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:59.549281Z",
     "start_time": "2020-05-22T19:54:59.543929Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check the value counts for the y_renovated column\n",
    "display(df['yr_renovated'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An extremely large percentage of the `yr_renovated` column has the value 0, meaning no renovation has occurred. Instead of removing the column, we can convert the values other than 0 to a 1. Giving us a usable feature instead of dropping one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:59.560741Z",
     "start_time": "2020-05-22T19:54:59.551001Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# transform the values other than 0 to a 1 in yr_renovated, and rename the column\n",
    "mask = df['yr_renovated'] != 0\n",
    "df.loc[mask, 'yr_renovated'] = 1\n",
    "df.rename(columns={'yr_renovated': 'renovated'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### sqft_basement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:59.847439Z",
     "start_time": "2020-05-22T19:54:59.562338Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# inspect the sqft_basement column by plotting a violinplot\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "sns.violinplot('sqft_basement', data=df, width=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:59.855520Z",
     "start_time": "2020-05-22T19:54:59.848888Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check the value counts for the sqft_basement column\n",
    "display(df['sqft_basement'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An extremely large percentage of the `yr_renovated` column has the value 0, meaning no renovation has occurred. Instead of removing the column, we can convert the values other than 0 to a 1. Giving us a usable feature instead of dropping one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:59.863813Z",
     "start_time": "2020-05-22T19:54:59.857183Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# transform the values other than 0 to a 1 in yr_renovated, and rename the column\n",
    "mask = df['sqft_basement'] != 0\n",
    "df.loc[mask, 'sqft_basement'] = 1\n",
    "df.rename(columns={'sqft_basement': 'basement'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### bedrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Another column we see an error in is the `bedrooms` columns. There is a huge skew, maybe due to a typing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:59.871151Z",
     "start_time": "2020-05-22T19:54:59.865301Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# output value counts\n",
    "display(df['bedrooms'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The house with 33 bedrooms may be an typing error, most likely a room with 3 bedrooms, not 33 which would be highly unusual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:59.877887Z",
     "start_time": "2020-05-22T19:54:59.872981Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# change the 33 bedroom house to a 3 bedroom\n",
    "df.loc[df['bedrooms'] == 33, 'bedrooms'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### NA Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:59.890273Z",
     "start_time": "2020-05-22T19:54:59.880577Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Output how many NA values we have\n",
    "display(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For the `waterfront` and `view` columns, we will replace the na values with 0, to signify no waterfront and no views respectively.\n",
    "\n",
    "For the `sqft_basement` column we will replace the na values with 0, to signify there is no basement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:54:59.905113Z",
     "start_time": "2020-05-22T19:54:59.893612Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# replace the na values with 0 in waterfront, view, sqft_basement\n",
    "df.replace(np.nan, 0, inplace=True)\n",
    "display(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since we've taken care of our null values, now we can focus on taking care of outliers which will significantly affect our linear regression in the future.\n",
    "\n",
    "We will first start with our `price` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:00.225672Z",
     "start_time": "2020-05-22T19:54:59.907455Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show boxplot of price column\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "\n",
    "sns.boxplot('price', data=df, ax=ax, showmeans=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There appears to be a significant amount of outliers. Let's identify how many, and whether we should eliminate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:00.239698Z",
     "start_time": "2020-05-22T19:55:00.227987Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# using iqr find outliers\n",
    "q1, q3 = np.quantile(df['price'], (.25, .75))\n",
    "iqr = q3 - q1\n",
    "low_bd, up_bd = q1 - iqr*1.5, q3 + iqr*1.5 # upper and lower bound of range\n",
    "mask = (df['price'] < low_bd) | (df['price'] > up_bd) # outliers mask\n",
    "\n",
    "outliers_mask = df.index[mask].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:00.249792Z",
     "start_time": "2020-05-22T19:55:00.242170Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# count our outliers\n",
    "display(f\"Outliers Count: {mask.sum()}\")\n",
    "display(f\"Outliers Percentage: {mask.sum()/df.shape[0]:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since we would only be removing approximately 5% of our dataset, 1158 data points, we will drop those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:00.527468Z",
     "start_time": "2020-05-22T19:55:00.251997Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# drop the data points which are price outliers and display a new boxplot of price\n",
    "df.drop(index=outliers_mask, inplace=True, errors='ignore') # ignore to allow re run\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "\n",
    "sns.boxplot(df['price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We've successfully removed the large amount of `price` outliers that were previously in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Type Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will convert columns which should be categorical to their correct type.\n",
    "\n",
    "- bedrooms\n",
    "- bathrooms\n",
    "- floors\n",
    "- waterfront\n",
    "- view\n",
    "- condition\n",
    "- grade\n",
    "- renovated\n",
    "- zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:00.550436Z",
     "start_time": "2020-05-22T19:55:00.529105Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# access and convert the categorical columns\n",
    "cat_cols = ['bedrooms', 'bathrooms', 'floors', 'waterfront', 'view',\n",
    "           'condition', 'grade', 'renovated', 'zipcode', 'yr_built']\n",
    "\n",
    "df.loc[:, cat_cols] = df.loc[:, cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:00.556870Z",
     "start_time": "2020-05-22T19:55:00.551976Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# verify conversion\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll use some guided questions to help us explore our data easier.\n",
    "\n",
    "1. Using location data, where are the highest valued properties?\n",
    "2. Are waterfront properties significantly expensive than non waterfront properties?\n",
    "3. Is there a relationship between condition and pricing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:00.956764Z",
     "start_time": "2020-05-22T19:55:00.558351Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import our libraries\n",
    "import plotly.express as px\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "# connect to online cdn\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:01.903782Z",
     "start_time": "2020-05-22T19:55:00.958236Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot pricing of houses across King County\n",
    "fig = px.scatter_mapbox(df.sort_values('price'), lat='lat', lon='long', color='price',\n",
    "                       color_continuous_scale=px.colors.sequential.BuGn,\n",
    "                       mapbox_style='carto-positron',\n",
    "                       center=dict(lat=df.lat.median(), lon=df.long.median()),\n",
    "                       title=\"House Prices in King County\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There appears to be higher concentrations of high valued houses towards the north of King County, With the majority of those located on the waterfront, there may be other contributing factors since there are high valued houses scattered around King County."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's inspect by zip code the median house price, to get a better picture at which areas have higher valued houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:01.906839Z",
     "start_time": "2020-05-22T19:55:01.905122Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:02.157048Z",
     "start_time": "2020-05-22T19:55:01.907955Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load in geojson of king county zip codes\n",
    "with open('kc_zips.geojson') as f:\n",
    "    geojson = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The King County zip codes geojson data was compiled from a larger dataset containing all US zip codes. The larger dataset can be found at: https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2019.html\n",
    "\n",
    "The downloaded data was then converted to a 1.4 GB geojson file by using https://mapshaper.org/. After which it was filtered for only zip codes in King County. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:02.173926Z",
     "start_time": "2020-05-22T19:55:02.159140Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create grouped dataframe with median house price for each zip code\n",
    "zipcode_df = df.groupby('zipcode').median().reset_index()\n",
    "zipcode_df['zipcode'] = zipcode_df['zipcode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.140182Z",
     "start_time": "2020-05-22T19:55:02.175369Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot median house price data on map by zipcode\n",
    "fig = px.choropleth_mapbox(zipcode_df, geojson=geojson, \n",
    "                          featureidkey='properties.ZCTA5CE10', locations='zipcode', \n",
    "                          color='price', mapbox_style='carto-positron', opacity=.4,\n",
    "                          center=dict(\n",
    "                              lat=zipcode_df.lat.median(),\n",
    "                              lon=zipcode_df.long.median()\n",
    "                          ), color_continuous_scale=px.colors.sequential.BuGn,  \n",
    "                          title=\"King County Median House Price by Zip Code\", )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The map shows us that the 3 zip codes with the highest median house prices are located in the centrally. **Those 3 zip codes are 98039, 98040, and 98004**.\n",
    "\n",
    "In the future it would be nice to reverse geocode the data we have, and see pricing by neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Waterfront Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.142177Z",
     "start_time": "2020-05-22T19:54:50.686Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# immport our libraries\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.142948Z",
     "start_time": "2020-05-22T19:54:50.690Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot two distplots of the different waterfront price values\n",
    "mask = df['waterfront'] == 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "sns.distplot(df.loc[mask, 'price'], norm_hist=True, ax=ax, label='waterfront')\n",
    "sns.distplot(df.loc[~mask, 'price'], norm_hist=True, ax=ax, label='non-waterfront')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These two groups don't look too different, but we can use some hypothesis testing to verify our assumptions.\n",
    "\n",
    "$\\mu_0:$ Waterfront House Mean Value\n",
    "\n",
    "$\\mu_1:$ Non-Waterfront House Mean Value\n",
    "\n",
    "$H_0: \\mu_0 = \\mu_1$\n",
    "\n",
    "$H_a: \\mu_0 \\ge \\mu_1$\n",
    "\n",
    "$\\alpha = $ 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.143697Z",
     "start_time": "2020-05-22T19:54:50.763Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# seperate our two populations and also show some 5-point summary of them\n",
    "mask = df['waterfront'] == 1\n",
    "waterfront = df.loc[mask, 'price']\n",
    "nonwaterfront = df.loc[~mask, 'price']\n",
    "\n",
    "display(df.groupby('waterfront').describe()['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our means are different by about $200,000, but our standard deviations are approximately the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.144545Z",
     "start_time": "2020-05-22T19:54:50.832Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run a welch's 2 sample t-test\n",
    "results = stats.ttest_ind(waterfront, nonwaterfront, equal_var=False)\n",
    "print(f\"T-Stat: {results.statistic:.3f}\", f\"P-Value: {results.pvalue:.8%}\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It appears that we do have a statistically significantly difference between the two populations. For our stakeholders we will provide a simple visualization to drive the point home that waterfront properties are valued higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.145641Z",
     "start_time": "2020-05-22T19:54:50.908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot barplot of the two populations average value wiht a confidence level of 95%\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "sns.barplot(x='waterfront', y='price', data=df, ax=ax)\n",
    "\n",
    "plt.title('King County Average House Value of Waterfront/Non-Waterfront Properties')\n",
    "\n",
    "plt.xticks([0, 1], ['Non-Waterfront', 'Waterfront'])\n",
    "locs, labels = plt.yticks()\n",
    "plt.yticks(locs, [f\"{loc/1000:n}\" for loc in locs])\n",
    "\n",
    "plt.ylabel(\"Price (thousands USD)\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### House Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.146871Z",
     "start_time": "2020-05-22T19:54:50.977Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# distplot of the pricing distribution by grade\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "sns.boxplot('grade', 'price', data=df, ax=ax)\n",
    "\n",
    "plt.xlabel('House Grade')\n",
    "plt.ylabel('House Value (Thousands USD)')\n",
    "plt.title(\"Boxplots of House Value by Grade\")\n",
    "\n",
    "# configure y axis\n",
    "ticks = np.arange(0, df['price'].max() + 100000, 100000)\n",
    "plt.yticks(ticks, [f\"{tick/1000:n}\" for tick in ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It appears there is some pattern between House Grade and price. It's extremely obvious by the fact that there is an increasing IQR for each House Grade. We can even see with an anova test, that these populations are completely differently priced.\n",
    "\n",
    "$\\alpha = $ 5%\n",
    "\n",
    "$H_0: \\mu_0 = \\mu_1 = \\mu_2 = \\mu_3 ... = \\mu_n$\n",
    "\n",
    "$H_a: \\mu_0 \\ne \\mu_1 \\ne \\mu_2 \\ne \\mu_3 ... \\ne \\mu_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.147928Z",
     "start_time": "2020-05-22T19:54:51.074Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Separate our samples by grade into a list\n",
    "samples = []\n",
    "for grade in df['grade'].unique():\n",
    "    mask = df['grade'] == grade\n",
    "    samples.append(df.loc[mask, 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.148956Z",
     "start_time": "2020-05-22T19:54:51.079Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# perform an anova test and output results\n",
    "results = stats.f_oneway(*samples)\n",
    "print(f\"T-Stat: {results.statistic:.3f}\", f\"P-Value: {results.pvalue:.8%}\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see here that we can reject the null hypothesis that the samples are derived from the same population, our test statistic is so large that our p-value is close to 0. For our stakeholders we will make this simple by\n",
    "creating a bar plot of the average house value for each house grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.149995Z",
     "start_time": "2020-05-22T19:54:51.158Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot bar plot of average house value by grade\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "sns.barplot('grade', 'price', data=df, ax=ax)\n",
    "plt.xlabel('House Grade')\n",
    "plt.ylabel('House Value (Thousands USD)')\n",
    "plt.title(\"Average House Value by Grade\")\n",
    "\n",
    "# configure y axis\n",
    "ticks = np.arange(0, df['price'].max(), 100000)\n",
    "plt.yticks(ticks, [f\"{tick/1000:n}\" for tick in ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.150823Z",
     "start_time": "2020-05-22T19:54:51.235Z"
    }
   },
   "outputs": [],
   "source": [
    "# check for any highly correlated variables\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "mask = np.abs(df.corr()) > .75\n",
    "\n",
    "sns.heatmap(np.abs(df.corr()), annot=True, fmt=\".0%\", square=True, ax=ax, mask=~mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not use sqft_above in our model, as it has a very high correlation with sqft_lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Only independent/predictor variable(s) is log-transformed**. Divide the coefficient by 100. This tells us that a 1% increase in the independent variable increases (or decreases) the dependent variable by (coefficient/100) units. Example: the coefficient is 0.198. 0.198/100 = 0.00198. For every 1% increase in the independent variable, our dependent variable increases by about 0.002. For x percent increase, multiply the coefficient by log(1.x). Example: For every 10% increase in the independent variable, our dependent variable increases by about 0.198 * log(1.10) = 0.02.  \n",
    "> \\- https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.151639Z",
     "start_time": "2020-05-22T19:54:51.466Z"
    }
   },
   "outputs": [],
   "source": [
    "# make two separate lists of our continuous and our categorical features\n",
    "continuous = ['sqft_living', 'sqft_lot', 'sqft_living15', 'sqft_lot15']\n",
    "categorical = ['bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'condition', \n",
    "               'grade', 'yr_built', 'renovated', 'zipcode', 'basement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.152216Z",
     "start_time": "2020-05-22T19:54:51.471Z"
    }
   },
   "outputs": [],
   "source": [
    "# display 5 point summary of price\n",
    "price_sum = df['price'].describe()\n",
    "display(price_sum.map(lambda val: f\"{val:.2f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.152869Z",
     "start_time": "2020-05-22T19:54:51.475Z"
    }
   },
   "outputs": [],
   "source": [
    "# log transform and scale our continuous variables\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean())/feature.std()\n",
    "\n",
    "cont_log = np.log(df[continuous])\n",
    "cont_log.columns = [f\"{col}_log\" for col in cont_log.columns]\n",
    "cont_log = cont_log.apply(normalize)\n",
    "\n",
    "# get dummies for categorical columns\n",
    "cat_cols = pd.get_dummies(df[categorical], drop_first=True)\n",
    "\n",
    "# combine our preprocessed data\n",
    "preprocessed = pd.concat([cont_log, cat_cols], axis=1)\n",
    "X = preprocessed\n",
    "y = df['price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.153630Z",
     "start_time": "2020-05-22T19:54:51.592Z"
    }
   },
   "outputs": [],
   "source": [
    "# import statsmodels and sklearn\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_validate\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start our regression we will build a simple linear regression model, which only relies on one feature. To help us decide, we will use a few jointplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.154288Z",
     "start_time": "2020-05-22T19:54:51.776Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot jointplot for continuous variables\n",
    "for col in cont_log.columns:\n",
    "    sns.jointplot(col, 'price', data=pd.concat([X, y], axis=1), kind='reg')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.155074Z",
     "start_time": "2020-05-22T19:54:51.781Z"
    }
   },
   "outputs": [],
   "source": [
    "# split our data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[['sqft_living_log']], y, random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.156105Z",
     "start_time": "2020-05-22T19:54:51.789Z"
    }
   },
   "outputs": [],
   "source": [
    "# create simple linear model using sqft_living and display summary\n",
    "simple_model = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "display(simple_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.156956Z",
     "start_time": "2020-05-22T19:54:51.793Z"
    }
   },
   "outputs": [],
   "source": [
    "# create our model\n",
    "linreg = LinearRegression()\n",
    "linreg = linreg.fit(X_train, y_train)\n",
    "\n",
    "# compute RMSE for our model\n",
    "mse_train = mean_squared_error(y_train, linreg.predict(X_train))\n",
    "mse_test = mean_squared_error(y_test, linreg.predict(X_test))\n",
    "\n",
    "rmse_train, rmse_test = np.sqrt([mse_train, mse_test])\n",
    "print(\"RMSE Train:\", (rmse_train), \"\\nRMSE Test:\", (rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see any major difference between our RMSE scores for our simple model, and our Adj. R-squared is .361.\n",
    "This model appears to not do the best, so next we will inspect modeling with more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.157789Z",
     "start_time": "2020-05-22T19:54:51.877Z"
    }
   },
   "outputs": [],
   "source": [
    "# verify residuals are normally distributed\n",
    "fig = sm.graphics.qqplot(simple_model.resid, fit=True, line='45')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.158675Z",
     "start_time": "2020-05-22T19:54:51.881Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(16, 9))\n",
    "sm.graphics.plot_regress_exog(simple_model, 'sqft_living_log', fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to note, that it appears the residuals of the model are normally distributed. And that there is may be some heteroskedacity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.160342Z",
     "start_time": "2020-05-22T19:54:52.042Z"
    }
   },
   "outputs": [],
   "source": [
    "# create model using 10 features\n",
    "regression = LinearRegression()\n",
    "selector = RFE(regression, n_features_to_select=10)\n",
    "selector = selector.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.161351Z",
     "start_time": "2020-05-22T19:54:52.046Z"
    }
   },
   "outputs": [],
   "source": [
    "# output selected columns\n",
    "selected_features = X.columns[selector.support_]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.162543Z",
     "start_time": "2020-05-22T19:54:52.050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using 5 kfolds we will cross validate and find the RMSE and R-squared\n",
    "linreg = LinearRegression()\n",
    "\n",
    "r2 = cross_validate(linreg, X[selected_features], y, scoring='r2', return_train_score=True)\n",
    "rmse = cross_validate(linreg, X[selected_features], y, scoring='neg_root_mean_squared_error', return_train_score=True)\n",
    "\n",
    "print(f\"Train Score: r2 = {(r2['train_score'].mean())}, rmse = {(-rmse['train_score'].mean())}\")\n",
    "print(f\"Test Score: r2 = {(r2['test_score'].mean())}, rmse = {(-rmse['test_score'].mean())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the selected 10 features, Our R-squared value shows that this model accounts for only 12% of the variation less than the previous 36% in our simple linear model, and our RMSE shows an increase compared to our previous model.\n",
    "\n",
    "Meaning our previous model did a better job of modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Wise Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.163650Z",
     "start_time": "2020-05-22T19:54:52.249Z"
    }
   },
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            mask = pvalues == worst_pval\n",
    "            worst_feature = np.array(included)[mask][0]\n",
    "            try:\n",
    "                included.remove(worst_feature)\n",
    "            except:\n",
    "                pass\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.164840Z",
     "start_time": "2020-05-22T19:54:52.255Z"
    }
   },
   "outputs": [],
   "source": [
    "# split our data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2309814)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.166542Z",
     "start_time": "2020-05-22T19:54:52.260Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('stepwise-features.pickle', 'rb') as f:\n",
    "    selected_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.167431Z",
     "start_time": "2020-05-22T19:54:52.266Z"
    }
   },
   "outputs": [],
   "source": [
    "# # perform our function over our entire preprocessed dataset\n",
    "# selected_features = stepwise_selection(X_train, y_train) # very expensive operation\n",
    "\n",
    "# with open('stepwise-features.pickle', 'wb') as f:\n",
    "#     pickle.dump(selected_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.168934Z",
     "start_time": "2020-05-22T19:54:52.275Z"
    }
   },
   "outputs": [],
   "source": [
    "# create our model\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.170195Z",
     "start_time": "2020-05-22T19:54:52.279Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using 10 kfolds we will cross validate and find the RMSE and R-squared\n",
    "linreg = LinearRegression()\n",
    "\n",
    "r2 = cross_validate(linreg, X[selected_features], y, scoring='r2', return_train_score=True, cv=10)\n",
    "rmse = cross_validate(linreg, X[selected_features], y, scoring='neg_root_mean_squared_error', return_train_score=True, cv=10)\n",
    "\n",
    "print(f\"Train Score: r2 = {(r2['train_score'].mean())}, rmse = {(-rmse['train_score'].mean())}\")\n",
    "print(f\"Test Score: r2 = {(r2['test_score'].mean())}, rmse = {(-rmse['test_score'].mean())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model we can see that our R-squared value is much greater than our previous models. 83% of the variation is explained by our model. Our RMSE has also decreased significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.171444Z",
     "start_time": "2020-05-22T19:54:52.374Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's find out the coefficients for our continuous variables\n",
    "display((model.params.sort_values(ascending=False)/100).loc[[f\"{val}_log\" for val in continuous]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every 1% increase in sqft_living, we see an increase in house value by \\$687.\n",
    "\n",
    "Meaning, a house with a sqft_living of 1,000, will be worth (206100) + (191516.78) = \\$397616.77, with everything else held constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:55:04.172575Z",
     "start_time": "2020-05-22T19:54:52.463Z"
    }
   },
   "outputs": [],
   "source": [
    "# top 3 unique independent variables\n",
    "model.params.sort_values(ascending=False).head(41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being in the zipcode 98039, adds $606,524.70 to house value.\n",
    "\n",
    "Having a house grade of 12, adds $322,168.21 to house value.\n",
    "\n",
    "Having a house that's near the waterfront, adds $140,481.69 to house value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
