{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"font-size:2em;\">Final Project Submission</b>\n",
    "\n",
    "* Student name: Edward Amor \n",
    "* Student pace: part time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: Victor Geislinger\n",
    "* Blog post URL: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A real estate company in the King County area wants to investigate house sales in order to predict pricing. Our task is to clean, explore, and model the housing data they have supplied to us in `kc_house_data.csv`, and identify house features which significantly effect house price. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To identify which house features significantly effect house price, we will use standard EDA practices, hypothesis testing, and regression modeling to come to our conclusions.\n",
    "\n",
    "For our client's consumption the results of our analysis will be condensed into a presentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our goal is to generate a multivariate linear regression model which as accurately as possible predicts the sale price of houses.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Acquisition\n",
    "2. Data Understanding\n",
    "  - Data Cleaning\n",
    "  - Data Exploration\n",
    "  - Data Visualization\n",
    "3. Modeling\n",
    "  - Feature Engineering\n",
    "    - Feature Transformation\n",
    "    - Feature Selection\n",
    "  - Training\n",
    "  - Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this project can be found in the file `kc_house_data.csv`.\n",
    "\n",
    "Within this repository is also `data_dictionary.csv` which describes the data features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our data dictionary the features of our dataset are as follows:\n",
    "\n",
    "| column        | description                                                  |\n",
    "| ------------- | ------------------------------------------------------------ |\n",
    "| id            | unique identified for a house                                |\n",
    "| date          | Date house was sold                                          |\n",
    "| price         | Price is prediction target                                   |\n",
    "| bedrooms      | Number of Bedrooms/House                                     |\n",
    "| bathrooms     | Number of bathrooms/bedrooms                                 |\n",
    "| sqft_living   | square footage of the home                                   |\n",
    "| sqft_lot      | square footage of the lot                                    |\n",
    "| floors        | Total floors (levels) in house                               |\n",
    "| waterfront    | House which has a view to a waterfront                       |\n",
    "| view          | Has been viewed                                              |\n",
    "| condition     | How good the condition is ( Overall )                        |\n",
    "| grade         | overall grade given to the housing unit                      |\n",
    "| sqft_above    | square footage of house apart from basement                  |\n",
    "| sqft_basement | square footage of the basement                               |\n",
    "| yr_built      | Built Year                                                   |\n",
    "| yr_renovated  | Year when house was renovated                                |\n",
    "| zipcode       | zip                                                          |\n",
    "| lat           | Latitude coordinate                                          |\n",
    "| long          | Longitude coordinate                                         |\n",
    "| sqft_living15 | The square footage of interior housing living space for the nearest 15 neighbors |\n",
    "| sqft_lot15    | The square footage of the land lots of the nearest 15 neighbors |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 20 columns most notable is the price feature which will be our target during linear regression.\n",
    "\n",
    "Another thing to note is we have location data. This could be used to provide some insight into pricing, but may also be of use when delivering key information to our client.\n",
    "\n",
    "Some notable things to look into while we explore the data:\n",
    "\n",
    "1. How does location and price relate?\n",
    "  - Since we are given location data, it would be insightful to see how geographic position affects pricing.\n",
    "2. Where are the houses with the poorest grades?\n",
    "  - It would be interesting if there exists a pattern between geographic position, grade, and pricing.\n",
    "3. Are waterfront houses in more demand?\n",
    "  - We can tell if demand is high, by the price compared to non-waterfront houses. (Hypothesis test?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section we will inspect our dataset cleaning up inconsistencies such as, null values, duplicates, and incorrect data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:16:04.929420Z",
     "start_time": "2020-05-19T07:16:04.017086Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:16:05.005964Z",
     "start_time": "2020-05-19T07:16:04.931291Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in dataframe and output dataframe info\n",
    "df = pd.read_csv(\"kc_house_data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our raw dataset contains **21597 records**, and has **21 features**.\n",
    "\n",
    "The data types found within our dataset are: `float64`, `int64`, `object`.\n",
    "\n",
    "Next we will inspect our features more closely, especially the ones which are of `object` data type. Just to make sure they're the correct data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:16:05.044704Z",
     "start_time": "2020-05-19T07:16:05.008886Z"
    }
   },
   "outputs": [],
   "source": [
    "# Output the first 5 rows\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `date` column should be transformed to the `datetime` data type instead of `object`.\n",
    "\n",
    "The `sqft_basement` column needs to be further inspected, the values appear to be `float` there may be some `string` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:16:05.093452Z",
     "start_time": "2020-05-19T07:16:05.047098Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert date column from string data type to a datetime\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:16:05.108664Z",
     "start_time": "2020-05-19T07:16:05.095782Z"
    }
   },
   "outputs": [],
   "source": [
    "# inspect the values of the sqft_basement column\n",
    "display(df['sqft_basement'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a '?' value, this may mean that the value is unknown. We will replace this with a null value, and then convert the column into a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:16:05.123306Z",
     "start_time": "2020-05-19T07:16:05.111638Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace ? with np.nan in the sqft_basement column and convert the column to float\n",
    "df['sqft_basement'] = df['sqft_basement'].replace('?', np.nan).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:16:05.136470Z",
     "start_time": "2020-05-19T07:16:05.125680Z"
    }
   },
   "outputs": [],
   "source": [
    "# redisplay the values in the sqft_basement column\n",
    "display(df['sqft_basement'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All our columns are now numeric, it's time to inspect for any interesting anomalies.\n",
    "\n",
    "We will start out by graphing our distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:16:18.242824Z",
     "start_time": "2020-05-19T07:16:05.139457Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot a distribution plot for each feature\n",
    "fig, ax = plt.subplots(7, 3, figsize=(16, 9*3)) # 21 sub plots\n",
    "\n",
    "for col, axes in zip(df.columns, ax.flatten()):\n",
    "    sns.distplot(df[col], kde=False, rug=True, ax=axes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns to disregard when cleaning:\n",
    "\n",
    "- `id`\n",
    "- `date`\n",
    "- `long`\n",
    "- `lat`\n",
    "- `zipcode`\n",
    "\n",
    "From the histograms it looks like we may want to drop the `yr_renovated` column, we will have to investigate further.\n",
    "\n",
    "There are quite a few columns which should be transformed into the `categorical` data type.\n",
    "\n",
    "One thing to notice is for some features such as `yr_renovated` and `sqft_lot` we have a lot of near zero values. Needs further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:16:18.734944Z",
     "start_time": "2020-05-19T07:16:18.244459Z"
    }
   },
   "outputs": [],
   "source": [
    "# inspect the yr_renovated column by plotting a violinplot\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "sns.violinplot('yr_renovated', data=df, width=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:16:18.744434Z",
     "start_time": "2020-05-19T07:16:18.736877Z"
    }
   },
   "outputs": [],
   "source": [
    "# check the value counts for the y_renovated column\n",
    "display(df['yr_renovated'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extremely large percentage of the `yr_renovated` column has the value 0, meaning no renovation has occurred. Instead of removing the column, we can convert the values other than 0 to a 1. Giving us a usable feature instead of dropping one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:17:24.057808Z",
     "start_time": "2020-05-19T07:17:24.027819Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform the values other than 0 to a 1 in yr_renovated, and rename the column\n",
    "mask = df['yr_renovated'] != 0\n",
    "df.loc[mask, 'yr_renovated'] = 1\n",
    "df.rename(columns={'yr_renovated': 'renovated'}, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
